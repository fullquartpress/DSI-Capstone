{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Price_Change</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Rate_of_Change</th>\n",
       "      <th>CV_Vectors</th>\n",
       "      <th>TFIDF_Vectors</th>\n",
       "      <th>Hash_Vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-02</td>\n",
       "      <td>India earns more from higher coffee exports in...</td>\n",
       "      <td>1.1506</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0 0 0 ... 0 0 0]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>Friesland raises stake in Indonesian subsidiar...</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022075</td>\n",
       "      <td>[0 0 0 ... 0 0 0]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>Nymex announces start date for soft commodity ...</td>\n",
       "      <td>1.1451</td>\n",
       "      <td>-0.0309</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.026276</td>\n",
       "      <td>[0 0 0 ... 0 0 0]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>India's largest coffee chain extends to Pakistan</td>\n",
       "      <td>1.1506</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>[0 0 0 ... 0 0 0]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-07</td>\n",
       "      <td>Honduran coffee sales Ugandan coffee funds Soy...</td>\n",
       "      <td>1.1506</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0 0 0 ... 0 0 0]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                              Title   Price  \\\n",
       "0  2007-01-02  India earns more from higher coffee exports in...  1.1506   \n",
       "1  2007-01-03  Friesland raises stake in Indonesian subsidiar...  1.1760   \n",
       "2  2007-01-04  Nymex announces start date for soft commodity ...  1.1451   \n",
       "3  2007-01-05  India's largest coffee chain extends to Pakistan   1.1506   \n",
       "4  2007-01-07  Honduran coffee sales Ugandan coffee funds Soy...  1.1506   \n",
       "\n",
       "   Price_Change  Direction  Rate_of_Change         CV_Vectors  \\\n",
       "0        0.0000          0        0.000000  [0 0 0 ... 0 0 0]   \n",
       "1        0.0254          0        0.022075  [0 0 0 ... 0 0 0]   \n",
       "2       -0.0309          0       -0.026276  [0 0 0 ... 0 0 0]   \n",
       "3        0.0055          0        0.004803  [0 0 0 ... 0 0 0]   \n",
       "4       -0.0000          0        0.000000  [0 0 0 ... 0 0 0]   \n",
       "\n",
       "             TFIDF_Vectors             Hash_Vectors  \n",
       "0  [0. 0. 0. ... 0. 0. 0.]  [0. 0. 0. ... 0. 0. 0.]  \n",
       "1  [0. 0. 0. ... 0. 0. 0.]  [0. 0. 0. ... 0. 0. 0.]  \n",
       "2  [0. 0. 0. ... 0. 0. 0.]  [0. 0. 0. ... 0. 0. 0.]  \n",
       "3  [0. 0. 0. ... 0. 0. 0.]  [0. 0. 0. ... 0. 0. 0.]  \n",
       "4  [0. 0. 0. ... 0. 0. 0.]  [0. 0. 0. ... 0. 0. 0.]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee = pd.read_csv('./working_coffee_csv.csv')\n",
    "coffee.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Price_Change</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Rate_of_Change</th>\n",
       "      <th>CV_Vectors</th>\n",
       "      <th>TFIDF_Vectors</th>\n",
       "      <th>Hash_Vectors</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-26</th>\n",
       "      <td>Futures Review: Arabica futures fall to one mo...</td>\n",
       "      <td>1.1107</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>[0 0 0 ... 0 0 0]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-27</th>\n",
       "      <td>Futures Review: Coffee ends narrowly mixed</td>\n",
       "      <td>1.1262</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>[0 0 0 ... 0 0 0]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28</th>\n",
       "      <td>Futures Review: Coffee moves away from recent ...</td>\n",
       "      <td>1.1262</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0 0 0 ... 0 0 0]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-29</th>\n",
       "      <td>IEG Vu: Easter email alert schedule, customer ...</td>\n",
       "      <td>1.1239</td>\n",
       "      <td>-0.0023</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002042</td>\n",
       "      <td>[0 0 0 ... 0 0 0]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>Futures Review: Arabica coffee hits 10-month l...</td>\n",
       "      <td>1.1262</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>[0 0 0 ... 0 0 0]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Title   Price  \\\n",
       "Date                                                                    \n",
       "2018-03-26  Futures Review: Arabica futures fall to one mo...  1.1107   \n",
       "2018-03-27         Futures Review: Coffee ends narrowly mixed  1.1262   \n",
       "2018-03-28  Futures Review: Coffee moves away from recent ...  1.1262   \n",
       "2018-03-29  IEG Vu: Easter email alert schedule, customer ...  1.1239   \n",
       "2018-04-03  Futures Review: Arabica coffee hits 10-month l...  1.1262   \n",
       "\n",
       "            Price_Change  Direction  Rate_of_Change         CV_Vectors  \\\n",
       "Date                                                                     \n",
       "2018-03-26        0.0034          0        0.003071  [0 0 0 ... 0 0 0]   \n",
       "2018-03-27        0.0155          0        0.013955  [0 0 0 ... 0 0 0]   \n",
       "2018-03-28       -0.0000          0        0.000000  [0 0 0 ... 0 0 0]   \n",
       "2018-03-29       -0.0023          0       -0.002042  [0 0 0 ... 0 0 0]   \n",
       "2018-04-03        0.0023          0        0.002046  [0 0 0 ... 0 0 0]   \n",
       "\n",
       "                      TFIDF_Vectors             Hash_Vectors  \n",
       "Date                                                          \n",
       "2018-03-26  [0. 0. 0. ... 0. 0. 0.]  [0. 0. 0. ... 0. 0. 0.]  \n",
       "2018-03-27  [0. 0. 0. ... 0. 0. 0.]  [0. 0. 0. ... 0. 0. 0.]  \n",
       "2018-03-28  [0. 0. 0. ... 0. 0. 0.]  [0. 0. 0. ... 0. 0. 0.]  \n",
       "2018-03-29  [0. 0. 0. ... 0. 0. 0.]  [0. 0. 0. ... 0. 0. 0.]  \n",
       "2018-04-03  [0. 0. 0. ... 0. 0. 0.]  [0. 0. 0. ... 0. 0. 0.]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee[\"Date\"] = pd.to_datetime(coffee['Date'])\n",
    "coffee.set_index('Date', inplace=True)\n",
    "coffee.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1465, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "tf = TfidfVectorizer()\n",
    "\n",
    "vector_tfidf = tf.fit(coffee['Title'])\n",
    "\n",
    "vector_tfidf_transformed = tf.fit_transform(coffee['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_tfidf_transformed = pd.DataFrame(vector_tfidf_transformed.toarray(), index=coffee.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1465, 3679)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_tfidf_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.concat([coffee, vector_tfidf_transformed],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1465, 3687)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Price_Change</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Rate_of_Change</th>\n",
       "      <th>CV_Vectors</th>\n",
       "      <th>TFIDF_Vectors</th>\n",
       "      <th>Hash_Vectors</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>3669</th>\n",
       "      <th>3670</th>\n",
       "      <th>3671</th>\n",
       "      <th>3672</th>\n",
       "      <th>3673</th>\n",
       "      <th>3674</th>\n",
       "      <th>3675</th>\n",
       "      <th>3676</th>\n",
       "      <th>3677</th>\n",
       "      <th>3678</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-02</th>\n",
       "      <td>India earns more from higher coffee exports in...</td>\n",
       "      <td>1.1506</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0 0 0 ... 0 0 0]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-03</th>\n",
       "      <td>Friesland raises stake in Indonesian subsidiar...</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022075</td>\n",
       "      <td>[0 0 0 ... 0 0 0]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 3687 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Title   Price  \\\n",
       "Date                                                                    \n",
       "2007-01-02  India earns more from higher coffee exports in...  1.1506   \n",
       "2007-01-03  Friesland raises stake in Indonesian subsidiar...  1.1760   \n",
       "\n",
       "            Price_Change  Direction  Rate_of_Change         CV_Vectors  \\\n",
       "Date                                                                     \n",
       "2007-01-02        0.0000          0        0.000000  [0 0 0 ... 0 0 0]   \n",
       "2007-01-03        0.0254          0        0.022075  [0 0 0 ... 0 0 0]   \n",
       "\n",
       "                      TFIDF_Vectors             Hash_Vectors    0    1  ...   \\\n",
       "Date                                                                    ...    \n",
       "2007-01-02  [0. 0. 0. ... 0. 0. 0.]  [0. 0. 0. ... 0. 0. 0.]  0.0  0.0  ...    \n",
       "2007-01-03  [0. 0. 0. ... 0. 0. 0.]  [0. 0. 0. ... 0. 0. 0.]  0.0  0.0  ...    \n",
       "\n",
       "            3669  3670  3671  3672  3673  3674  3675  3676  3677  3678  \n",
       "Date                                                                    \n",
       "2007-01-02   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2007-01-03   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[2 rows x 3687 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(temp_df.shape)\n",
    "\n",
    "temp_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = temp_df.drop(['Title', 'Price', 'Direction', 'CV_Vectors', 'TFIDF_Vectors','Hash_Vectors'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price_Change</th>\n",
       "      <th>Rate_of_Change</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>3669</th>\n",
       "      <th>3670</th>\n",
       "      <th>3671</th>\n",
       "      <th>3672</th>\n",
       "      <th>3673</th>\n",
       "      <th>3674</th>\n",
       "      <th>3675</th>\n",
       "      <th>3676</th>\n",
       "      <th>3677</th>\n",
       "      <th>3678</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-29</th>\n",
       "      <td>-0.0023</td>\n",
       "      <td>-0.002042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 3681 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Price_Change  Rate_of_Change    0    1    2    3    4    5  \\\n",
       "Date                                                                     \n",
       "2018-03-29       -0.0023       -0.002042  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2018-04-03        0.0023        0.002046  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                   6    7  ...   3669  3670  3671  3672  3673  3674  3675  \\\n",
       "Date                       ...                                              \n",
       "2018-03-29  0.000000  0.0  ...    0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2018-04-03  0.225947  0.0  ...    0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "            3676  3677  3678  \n",
       "Date                          \n",
       "2018-03-29   0.0   0.0   0.0  \n",
       "2018-04-03   0.0   0.0   0.0  \n",
       "\n",
       "[2 rows x 3681 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intializing intercept...\n",
      "Intializing beta..\n",
      "Intializing sigma..\n",
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as cup_of_joe:\n",
    "    print(\"Intializing intercept...\")\n",
    "    intercept = pm.Normal('Intercept', mu=0, sd=10)\n",
    "    \n",
    "    print(\"Intializing beta..\") \n",
    "    beta = pm.Normal('beta', mu=0, sd=10, shape=3681)\n",
    "    \n",
    "    print(\"Intializing sigma..\") \n",
    "    sigma = pm.HalfNormal('price_std', sd=1)\n",
    "    \n",
    "    mu = intercept\n",
    "    for i in range(3679):\n",
    "        mu += beta[i]*new_df.iloc[:,i]\n",
    "    \n",
    "    price = pm.Normal('Price', mu=mu, sd=sigma, observed=temp_df['Price'])\n",
    "\n",
    "print(\"All Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cup_of_joe:\n",
    "    start = pm.find_MAP()\n",
    "    trace = pm.sample(3500, start=start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pm.Model() as cup_of_joe:\n",
    "#     intercept = pm.Normal('Intercept', mu=0, sd=10)\n",
    "#     beta = pm.Normal('beta', mu=0, sd=10, shape=3679)\n",
    "#     sigma = pm.HalfNormal('price_std', sd=1)\n",
    "    \n",
    "#     mu = intercept + np.dot(beta, temp_df.iloc[:, 5:])\n",
    "    \n",
    "#     price = pm.Normal('Price', mu=mu, sd=sigma, observed=temp_df['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with cup_of_joe:\n",
    "#     start = pm.find_MAP()\n",
    "#     trace = pm.sample(3500, start=start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intializing intercept...\n",
      "Intializing beta..\n",
      "Intializing sigma..\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as cup_of_joe:\n",
    "    print(\"Intializing intercept...\")\n",
    "    intercept = pm.Normal('Intercept', mu=0, sd=10)\n",
    "    \n",
    "    print(\"Intializing beta..\") \n",
    "    beta = pm.Normal('beta', mu=0, sd=10, shape=3679)\n",
    "    \n",
    "    print(\"Intializing sigma..\") \n",
    "    sigma = pm.HalfNormal('price_std', sd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorType(float64, vector)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intializing intercept...\n",
      "Intializing beta..\n",
      "Intializing sigma..\n",
      "... working sucka ...\n",
      "... working sucka ...\n",
      "... working sucka ...\n",
      "... working sucka ...\n",
      "... working sucka ...\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as cup_of_joe:\n",
    "    print(\"Intializing intercept...\")\n",
    "    intercept = pm.Normal('Intercept', mu=0, sd=10)\n",
    "    \n",
    "    print(\"Intializing beta..\") \n",
    "    beta = pm.Normal('beta', mu=0, sd=10, shape=3679)\n",
    "    \n",
    "    print(\"Intializing sigma..\") \n",
    "    sigma = pm.HalfNormal('price_std', sd=1)\n",
    "    \n",
    "        betas = []\n",
    "\n",
    "        for index in range(3679):\n",
    "\n",
    "            if index % 1000 == 0:\n",
    "                print(\"... working sucka ...\")\n",
    "            betas.append(beta[index])\n",
    "\n",
    "        betas_np = np.array(betas)\n",
    "\n",
    "        x_vals = []\n",
    "\n",
    "        for index in range(3679):\n",
    "\n",
    "            if index % 1000 == 0:\n",
    "                print(\"... working sucka ...\")\n",
    "            x_vals.append(temp_df.iloc[:, 5:])\n",
    "\n",
    "        x_vals_np = np.array(x_vals)\n",
    "    \n",
    "    mu = intercept + np.dot(betas_np, x_vals_np)\n",
    "    \n",
    "    price = pm.Normal('Price', mu=mu, sd=sigma, observed=temp_df['Price'])\n",
    "\n",
    "    \n",
    "    #partial = np.sum([index, col for index, col in enumerate(temp_df.iloc[:, 5:].columns.tolist())]))\n",
    "    \n",
    "    # mu = intercept + np.dot(beta, temp_df.iloc[:, 5:])\n",
    "    \n",
    "    #price = pm.Normal('Price', mu=mu, sd=sigma, observed=temp_df['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cup_of_joe:\n",
    "    start = pm.find_MAP()\n",
    "    trace = pm.sample(3500, start=start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x_vals = []\n",
    "\n",
    "# for index in range(3679):\n",
    "        \n",
    "#     if index % 100 == 0:\n",
    "#         print(\"... working sucka ...\")\n",
    "#     x_vals.append(temp_df[index])\n",
    "        \n",
    "# x_vals_np = np.array(x_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_vals_np.shape)\n",
    "print(betas_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pm.Model() as cup_of_joe:\n",
    "    print(\"Intializing intercept...\")\n",
    "    intercept = pm.Normal('Intercept', mu=0, sd=10)\n",
    "    \n",
    "    print(\"Intializing beta..\") \n",
    "    beta = pm.Normal('beta', mu=0, sd=10, shape=3679)\n",
    "    \n",
    "    print(\"Intializing sigma..\") \n",
    "    sigma = pm.HalfNormal('price_std', sd=1)\n",
    "    \n",
    "    mu = intercept + np.dot(betas_np, x_vals_np)\n",
    "    \n",
    "    price = pm.Normal('Price', mu=mu, sd=sigma, observed=temp_df['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = intercept + np.dot(betas_np, temp_df.iloc[:, 5:]) #need to match index and iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = CountVectorizer()\n",
    "\n",
    "# vector_cv = cv.fit_transform(coffee['Title'])\n",
    "\n",
    "# vector_transformed = cv.fit_transform(coffee['Title'])\n",
    "\n",
    "# coffee[\"CV_Vectors\"] = list(vector_transformed.toarray())\n",
    "\n",
    "# coffee.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashed = HashingVectorizer()\n",
    "\n",
    "# vector_hashed_transformed = hashed.fit_transform(coffee['Title'])\n",
    "\n",
    "# coffee['Hash_Vectors'] = list(vector_hashed_transformed.toarray())\n",
    "# coffee.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coffee.to_csv('working_coffee_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack the columns - start with TFIDF Vectors save as a new DF join with the current coffee DF. need truncated SVD.\n",
    "# can run TFIDF (or any other column) through PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as cup_of_joe:\n",
    "    intercept = pm.Normal('Intercept', mu=0, sd=10)\n",
    "    beta = pm.Normal('beta', mu=0, sd=10, shape=3679)\n",
    "    sigma = pm.HalfNormal('price_std', sd=1)\n",
    "    \n",
    "    #mu = intercept + for i in range(3678):\n",
    "    #    beta[i]\n",
    "    #    temp_df[i]\n",
    "    \n",
    "    mu = intercept + np.dot(beta, temp_df.iloc[:, 5:])\n",
    "    \n",
    "    \n",
    "    price = pm.Normal('Price', mu=mu, sd=sigma, observed=temp_df['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cup_of_joe:\n",
    "    start = pm.find_MAP()\n",
    "    trace = pm.sample(3500, start=start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(temp_df.columns[6:].tolist())\n",
    "temp_df.columns[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept + np.dot(beta, temp_df.iloc[:, 5:].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(beta[index], col) for index, col in enumerate(temp_df.columns.tolist())]\n",
    "# temp_df[temp_df.columns[5:]].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pm.Model() as cup_of_joe:\n",
    "#     print(\"Intializing intercept...\")\n",
    "#     intercept = pm.Normal('Intercept', mu=0, sd=10)\n",
    "    \n",
    "#     print(\"Intializing beta..\") \n",
    "#     beta = pm.Normal('beta', mu=0, sd=10, shape=3679)\n",
    "    \n",
    "#     print(\"Intializing sigma..\") \n",
    "#     sigma = pm.HalfNormal('price_std', sd=1)\n",
    "    \n",
    "#     betas = []\n",
    "\n",
    "#     for index in range(3679):\n",
    "\n",
    "#       if index % 1000 == 0:\n",
    "#         print(\"... working sucka ...\")\n",
    "#       betas.append(beta[index])\n",
    "\n",
    "#       betas_np = np.array(betas)\n",
    "\n",
    "#     x_vals = []\n",
    "\n",
    "#     for index in range(3679):\n",
    "\n",
    "#       if index % 1000 == 0:\n",
    "#         print(\"... working sucka ...\")\n",
    "#       x_vals.append(temp_df.iloc[:, 5:])\n",
    "\n",
    "#       x_vals_np = np.array(x_vals)\n",
    "    \n",
    "#     mu = intercept + np.dot(betas_np, x_vals_np)\n",
    "    \n",
    "#     price = pm.Normal('Price', mu=mu, sd=sigma, observed=temp_df['Price'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
